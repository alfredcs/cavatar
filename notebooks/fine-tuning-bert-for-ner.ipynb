{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-29T14:48:48.726563Z",
     "iopub.status.busy": "2023-09-29T14:48:48.726316Z",
     "iopub.status.idle": "2023-09-29T14:48:49.041760Z",
     "shell.execute_reply": "2023-09-29T14:48:49.040870Z",
     "shell.execute_reply.started": "2023-09-29T14:48:48.726539Z"
    }
   },
   "source": [
    "# Fine-Tuning BERT for NER\n",
    "\n",
    "This Python 3 environment comes with many helpful analytics libraries installed\n",
    "It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python For example, here's several helpful packages to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning BERT for Named Entity Recognition\n",
    "\n",
    "This notebook covers fine-tuning a pretrained BERT model for Named Entity Recognition (NER) on the CoNLL-2003 dataset. \n",
    "\n",
    "NER is a common NLP task that involves identifying and classifying key entities (people, organizations, locations etc.) in text. It is an essential step for many downstream applications.\n",
    "\n",
    "We will use Hugging Face's implementations of BERT and Trainer to fine-tune a model to perform NER. The key steps are:\n",
    "\n",
    "1. Prepare training data and map labels  \n",
    "2. Load pretrained BERT model and tokenizer\n",
    "3. Define training arguments and trainer\n",
    "4. Fine-tune model on training data \n",
    "5. Evaluate on validation data\n",
    "\n",
    "The trained model can extract named entities from text by encoding the text and applying the model's token classification head.\n",
    "\n",
    "This provides a simple template for fine-tuning transformer models like BERT for sequence tagging tasks like NER. The same principles can be applied to other datasets and use cases as well.\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:48:49.043979Z",
     "iopub.status.busy": "2023-09-29T14:48:49.043351Z",
     "iopub.status.idle": "2023-09-29T14:48:56.560663Z",
     "shell.execute_reply": "2023-09-29T14:48:56.559760Z",
     "shell.execute_reply.started": "2023-09-29T14:48:49.043946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44515c02ca7649a3974ed0214354385e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525fbe6df9ea49328201d73f0ebd61f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset conll2003/conll2003 (download: 959.94 KiB, generated: 9.78 MiB, post-processed: Unknown size, total: 10.72 MiB) to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df2beb444fc4430acd92361f90806c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3251 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3454 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conll2003 downloaded and prepared to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a196c1225161429daad6787bd4b33183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14042\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3251\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3454\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the CoNLL-2003 dataset using the 'datasets' library.\n",
    "dataset = load_dataset('conll2003')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:48:56.562791Z",
     "iopub.status.busy": "2023-09-29T14:48:56.562089Z",
     "iopub.status.idle": "2023-09-29T14:48:56.572558Z",
     "shell.execute_reply": "2023-09-29T14:48:56.571303Z",
     "shell.execute_reply.started": "2023-09-29T14:48:56.562758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': Value(dtype='string', id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'pos_tags': Sequence(feature=ClassLabel(num_classes=47, names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None), 'chunk_tags': Sequence(feature=ClassLabel(num_classes=23, names=['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP'], id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "# Printing the features of the training dataset.\n",
    "print(dataset['train'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:48:56.576711Z",
     "iopub.status.busy": "2023-09-29T14:48:56.576303Z",
     "iopub.status.idle": "2023-09-29T14:48:56.611135Z",
     "shell.execute_reply": "2023-09-29T14:48:56.610170Z",
     "shell.execute_reply.started": "2023-09-29T14:48:56.576664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the label names from the 'ner_tags' feature.\n",
    "label_names = dataset['train'].features['ner_tags'].feature.names\n",
    "\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:48:56.613961Z",
     "iopub.status.busy": "2023-09-29T14:48:56.613273Z",
     "iopub.status.idle": "2023-09-29T14:48:56.623275Z",
     "shell.execute_reply": "2023-09-29T14:48:56.622127Z",
     "shell.execute_reply.started": "2023-09-29T14:48:56.613931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:48:56.625261Z",
     "iopub.status.busy": "2023-09-29T14:48:56.624519Z",
     "iopub.status.idle": "2023-09-29T14:48:59.953903Z",
     "shell.execute_reply": "2023-09-29T14:48:59.952990Z",
     "shell.execute_reply.started": "2023-09-29T14:48:56.625218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92aac08371c41b0b898a63c91d3618d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7996af085d314ea29d4442d19c96c0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a022355db4494492959d090d22cdb23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9541520d06684cffabdc02084e8ed85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Define the checkpoint you want to use for the tokenizer.\n",
    "checkpoint = 'distilbert-base-cased'\n",
    "\n",
    "# Create a tokenizer instance by loading the pre-trained checkpoint.\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:48:59.955384Z",
     "iopub.status.busy": "2023-09-29T14:48:59.954877Z",
     "iopub.status.idle": "2023-09-29T14:48:59.970195Z",
     "shell.execute_reply": "2023-09-29T14:48:59.969352Z",
     "shell.execute_reply.started": "2023-09-29T14:48:59.955352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} \n",
      "--------------------------------------------------------------------------------------\n",
      " ['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]'] \n",
      "--------------------------------------------------------------------------------------\n",
      " [None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the first training example from the dataset \n",
    "token = tokenizer(dataset['train'][0]['tokens'], is_split_into_words = True)\n",
    "\n",
    "# Print the tokenizer object, the tokenized tokens, and the word IDs\n",
    "print(token, '\\n--------------------------------------------------------------------------------------\\n', \n",
    "      token.tokens(),'\\n--------------------------------------------------------------------------------------\\n',\n",
    "      token.word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:48:59.972300Z",
     "iopub.status.busy": "2023-09-29T14:48:59.971656Z",
     "iopub.status.idle": "2023-09-29T14:48:59.985631Z",
     "shell.execute_reply": "2023-09-29T14:48:59.984714Z",
     "shell.execute_reply.started": "2023-09-29T14:48:59.972269Z"
    }
   },
   "outputs": [],
   "source": [
    "def align_target(labels, word_ids):\n",
    "    # Define a mapping from beginning (B-) labels to inside (I-) labels\n",
    "    begin2inside = {\n",
    "        1: 2,  # B-LOC -> I-LOC\n",
    "        3: 4,  # B-MISC -> I-MISC\n",
    "        5: 6,  # B-ORG -> I-ORG\n",
    "        7: 8    # B-PER -> I-PER\n",
    "    }\n",
    "\n",
    "    # Initialize an empty list to store aligned labels and a variable to track the last word\n",
    "    align_labels = []\n",
    "    last_word = None\n",
    "\n",
    "    # Iterate through the word_ids\n",
    "    for word in word_ids:\n",
    "        if word is None:\n",
    "            label = -100  # Set label to -100 for None word_ids\n",
    "        elif word != last_word:\n",
    "            label = labels[word]  # Use the label corresponding to the current word_id\n",
    "        else:\n",
    "            label = labels[word]\n",
    "            # Change B- to I- if the previous word is the same\n",
    "            if label in begin2inside:\n",
    "                label = begin2inside[label]  # Map B- to I-\n",
    "\n",
    "        # Append the label to the align_labels list and update last_word\n",
    "        align_labels.append(label)\n",
    "        last_word = word\n",
    "\n",
    "    return align_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:48:59.987899Z",
     "iopub.status.busy": "2023-09-29T14:48:59.987260Z",
     "iopub.status.idle": "2023-09-29T14:48:59.997327Z",
     "shell.execute_reply": "2023-09-29T14:48:59.996382Z",
     "shell.execute_reply.started": "2023-09-29T14:48:59.987869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]'] \n",
      "--------------------------------------------------------------------------------------\n",
      " [3, 0, 7, 0, 0, 0, 7, 0, 0] \n",
      "--------------------------------------------------------------------------------------\n",
      " [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "# Extract labels and word_ids\n",
    "labels = dataset['train'][0]['ner_tags']\n",
    "word_ids = token.word_ids()\n",
    "\n",
    "# Use the align_target function to align labels\n",
    "aligned_target = align_target(labels, word_ids)\n",
    "\n",
    "# Print tokenized tokens, original labels, and aligned labels\n",
    "print(token.tokens(), '\\n--------------------------------------------------------------------------------------\\n',\n",
    "      labels, '\\n--------------------------------------------------------------------------------------\\n',\n",
    "      aligned_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:00.006809Z",
     "iopub.status.busy": "2023-09-29T14:49:00.005332Z",
     "iopub.status.idle": "2023-09-29T14:49:00.027880Z",
     "shell.execute_reply": "2023-09-29T14:49:00.026341Z",
     "shell.execute_reply.started": "2023-09-29T14:49:00.006777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\tNone\n",
      "EU\tB-ORG\n",
      "rejects\tO\n",
      "German\tB-MISC\n",
      "call\tO\n",
      "to\tO\n",
      "boycott\tO\n",
      "British\tB-MISC\n",
      "la\tO\n",
      "##mb\tO\n",
      ".\tO\n",
      "[SEP]\tNone\n"
     ]
    }
   ],
   "source": [
    "# Create a list of aligned labels using label names\n",
    "aligned_labels = [label_names[t] if t >= 0 else None for t in aligned_target]\n",
    "\n",
    "# Loop through tokens and aligned labels and print them\n",
    "for x, y in zip(token.tokens(), aligned_labels):\n",
    "    print(f\"{x}\\t{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:00.029813Z",
     "iopub.status.busy": "2023-09-29T14:49:00.028767Z",
     "iopub.status.idle": "2023-09-29T14:49:00.042949Z",
     "shell.execute_reply": "2023-09-29T14:49:00.042045Z",
     "shell.execute_reply.started": "2023-09-29T14:49:00.029571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\tNone\n",
      "Ger\tB-MISC\n",
      "##man\tI-MISC\n",
      "call\tO\n",
      "to\tO\n",
      "Micro\tB-ORG\n",
      "##so\tI-ORG\n",
      "##ft\tI-ORG\n",
      "[SEP]\tNone\n"
     ]
    }
   ],
   "source": [
    "# Define fake input data\n",
    "words = ['[CLS]', 'Ger', '##man', 'call', 'to', 'Micro', '##so', '##ft', '[SEP]']\n",
    "word_ids = [None, 0, 0, 1, 2, 3, 3, 3, None]\n",
    "labels = [7, 0, 0, 3, 4]\n",
    "\n",
    "# Use the align_target function to align labels\n",
    "aligned_target = align_target(labels, word_ids)\n",
    "\n",
    "# Create a list of aligned labels using label names\n",
    "aligned_labels = [label_names[t] if t >= 0 else None for t in aligned_target]\n",
    "\n",
    "# Loop through words and aligned labels and print them\n",
    "for x, y in zip(words, aligned_labels):\n",
    "    print(f\"{x}\\t{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:00.046846Z",
     "iopub.status.busy": "2023-09-29T14:49:00.045727Z",
     "iopub.status.idle": "2023-09-29T14:49:00.067315Z",
     "shell.execute_reply": "2023-09-29T14:49:00.065910Z",
     "shell.execute_reply.started": "2023-09-29T14:49:00.046812Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    # Tokenize the input batch\n",
    "    tokenized_inputs = tokenizer(batch['tokens'], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    # Extract the labels batch from the input batch\n",
    "    labels_batch = batch['ner_tags']\n",
    "\n",
    "    # Initialize a list to store aligned targets for each example in the batch\n",
    "    aligned_targets_batch = []\n",
    "\n",
    "    # Iterate through each example and align the labels\n",
    "    for i, labels in enumerate(labels_batch):\n",
    "        # Extract the word_ids for the current example\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "\n",
    "        # Use the align_target function to align the labels\n",
    "        aligned_targets_batch.append(align_target(labels, word_ids))\n",
    "\n",
    "    # Add the aligned labels to the tokenized inputs under the key \"labels\"\n",
    "    tokenized_inputs[\"labels\"] = aligned_targets_batch\n",
    "\n",
    "    # Return the tokenized inputs, including aligned labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:00.068993Z",
     "iopub.status.busy": "2023-09-29T14:49:00.068438Z",
     "iopub.status.idle": "2023-09-29T14:49:05.401791Z",
     "shell.execute_reply": "2023-09-29T14:49:05.399539Z",
     "shell.execute_reply.started": "2023-09-29T14:49:00.068963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6dc5308a2f4dc8aa8b99f9b132c0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90372cbcf26b4b289c710c8092130290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78ebbc164784d0685e7717be3e1ff38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_fn, batched=True, remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:05.408766Z",
     "iopub.status.busy": "2023-09-29T14:49:05.406457Z",
     "iopub.status.idle": "2023-09-29T14:49:14.625961Z",
     "shell.execute_reply": "2023-09-29T14:49:14.624948Z",
     "shell.execute_reply.started": "2023-09-29T14:49:05.408702Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7270, 22961,  1528,  1840,  1106, 21423,  1418,  2495, 12913,\n",
       "           119,   102],\n",
       "        [  101,  1943, 14428,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
       "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "# Create a DataCollatorForTokenClassification object\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "# Testing data using the data collator\n",
    "batch = data_collator([tokenized_dataset['train'][i] for i in range(2)])\n",
    "\n",
    "# Display the resulting batch\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:14.628496Z",
     "iopub.status.busy": "2023-09-29T14:49:14.627275Z",
     "iopub.status.idle": "2023-09-29T14:49:26.330389Z",
     "shell.execute_reply": "2023-09-29T14:49:26.329300Z",
     "shell.execute_reply.started": "2023-09-29T14:49:14.628460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=bd3387c8fc9f7eff4fc3a59a5365958508453159f3aed05f6cbc6c4b0ff29cca\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "# Install the seqeval library for evaluating sequence tasks\n",
    "!pip install seqeval ; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:26.332723Z",
     "iopub.status.busy": "2023-09-29T14:49:26.332376Z",
     "iopub.status.idle": "2023-09-29T14:49:27.072128Z",
     "shell.execute_reply": "2023-09-29T14:49:27.071158Z",
     "shell.execute_reply.started": "2023-09-29T14:49:26.332685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf346b1fad8f44a4a3272ba3dabaa6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MISC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
       " 'ORG': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
       " 'overall_precision': 0.0,\n",
       " 'overall_recall': 0.0,\n",
       " 'overall_f1': 0.0,\n",
       " 'overall_accuracy': 0.6666666666666666}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the seqeval metric from Hugging Face's datasets library\n",
    "from datasets import load_metric  \n",
    "\n",
    "# Load the seqeval metric which can evaluate NER and other sequence tasks\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "# Example usage: compute metric on a sample predictions and reference list \n",
    "# predictions and references should be a list of lists containing predicted and true token labels\n",
    "\n",
    "# List of List Input  \n",
    "metric.compute(predictions = [['O' , 'B-ORG' , 'I-ORG']], \n",
    "               references = [['O' , 'B-MISC' , 'I-ORG']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:27.074465Z",
     "iopub.status.busy": "2023-09-29T14:49:27.073454Z",
     "iopub.status.idle": "2023-09-29T14:49:27.083093Z",
     "shell.execute_reply": "2023-09-29T14:49:27.081728Z",
     "shell.execute_reply.started": "2023-09-29T14:49:27.074432Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to compute evaluation metrics from model logits and true labels\n",
    "def compute_metrics(logits_and_labels):\n",
    "\n",
    "  # Unpack the logits and labels\n",
    "  logits, labels = logits_and_labels \n",
    "  \n",
    "  # Get predictions from the logits\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "  # Remove ignored index (special tokens)\n",
    "  str_labels = [\n",
    "    [label_names[t] for t in label if t!=-100] for label in labels\n",
    "  ]\n",
    "  \n",
    "  str_preds = [\n",
    "    [label_names[p] for (p, t) in zip(prediction, label) if t != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "  ]\n",
    "\n",
    "  # Compute metrics\n",
    "  results = metric.compute(predictions=str_preds, references=str_labels)\n",
    "  \n",
    "  # Extract key metrics\n",
    "  return {\n",
    "    \"precision\": results[\"overall_precision\"],\n",
    "    \"recall\": results[\"overall_recall\"], \n",
    "    \"f1\": results[\"overall_f1\"],\n",
    "    \"accuracy\": results[\"overall_accuracy\"]  \n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:27.084786Z",
     "iopub.status.busy": "2023-09-29T14:49:27.084455Z",
     "iopub.status.idle": "2023-09-29T14:49:27.094943Z",
     "shell.execute_reply": "2023-09-29T14:49:27.094033Z",
     "shell.execute_reply.started": "2023-09-29T14:49:27.084755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC'} \n",
      "--------------------\n",
      " {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n"
     ]
    }
   ],
   "source": [
    "# Create mapping from label ID to label string name\n",
    "id2label = {k: v for k, v in enumerate(label_names)} \n",
    "\n",
    "# Create reverse mapping from label name to label ID\n",
    "label2id = {v: k for k, v in enumerate(label_names)}\n",
    "\n",
    "print(id2label , '\\n--------------------\\n' , label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:27.097552Z",
     "iopub.status.busy": "2023-09-29T14:49:27.096642Z",
     "iopub.status.idle": "2023-09-29T14:49:29.799171Z",
     "shell.execute_reply": "2023-09-29T14:49:29.798275Z",
     "shell.execute_reply.started": "2023-09-29T14:49:27.097518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fdf57c3e204a8788b77e67413bfd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained token classification model from Transformers \n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "# Initialize model object with pretrained weights\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "  checkpoint,\n",
    "\n",
    "  # Pass in label mappings\n",
    "  id2label=id2label,  \n",
    "  label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:29.800993Z",
     "iopub.status.busy": "2023-09-29T14:49:29.800666Z",
     "iopub.status.idle": "2023-09-29T14:49:29.839152Z",
     "shell.execute_reply": "2023-09-29T14:49:29.838147Z",
     "shell.execute_reply.started": "2023-09-29T14:49:29.800962Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure training arguments using TrainigArguments class\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  # Location to save fine-tuned model \n",
    "  output_dir = \"fine_tuned_model\",\n",
    "\n",
    "  # Evaluate each epoch\n",
    "  evaluation_strategy = \"epoch\",\n",
    "\n",
    "  # Learning rate for Adam optimizer\n",
    "  learning_rate = 2e-5, \n",
    "  \n",
    "  # Batch sizes for training and evaluation\n",
    "  per_device_train_batch_size = 16,\n",
    "  per_device_eval_batch_size = 16,\n",
    "\n",
    "  # Number of training epochs\n",
    "  num_train_epochs = 3,\n",
    "\n",
    "  # L2 weight decay regularization\n",
    "  weight_decay = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:29.841865Z",
     "iopub.status.busy": "2023-09-29T14:49:29.841318Z",
     "iopub.status.idle": "2023-09-29T14:49:35.215400Z",
     "shell.execute_reply": "2023-09-29T14:49:35.214479Z",
     "shell.execute_reply.started": "2023-09-29T14:49:29.841833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Trainer object for model training\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "  # Model to train\n",
    "  model=model, \n",
    "  \n",
    "  # Training arguments\n",
    "  args=training_args,\n",
    "\n",
    "  # Training and validation datasets\n",
    "  train_dataset=tokenized_dataset[\"train\"],\n",
    "  eval_dataset=tokenized_dataset[\"validation\"],\n",
    "\n",
    "  # Tokenizer\n",
    "  tokenizer=tokenizer,\n",
    "\n",
    "  # Custom metric function\n",
    "  compute_metrics=compute_metrics,\n",
    "\n",
    "  # Data collator\n",
    "  data_collator=data_collator \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:49:35.216818Z",
     "iopub.status.busy": "2023-09-29T14:49:35.216515Z",
     "iopub.status.idle": "2023-09-29T14:55:15.112378Z",
     "shell.execute_reply": "2023-09-29T14:55:15.110830Z",
     "shell.execute_reply.started": "2023-09-29T14:49:35.216789Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230929_145151-urjhoc2d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/afxteam/huggingface/runs/urjhoc2d' target=\"_blank\">graceful-sound-21</a></strong> to <a href='https://wandb.ai/afxteam/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/afxteam/huggingface' target=\"_blank\">https://wandb.ai/afxteam/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/afxteam/huggingface/runs/urjhoc2d' target=\"_blank\">https://wandb.ai/afxteam/huggingface/runs/urjhoc2d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2634/2634 02:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.243600</td>\n",
       "      <td>0.082009</td>\n",
       "      <td>0.878635</td>\n",
       "      <td>0.910131</td>\n",
       "      <td>0.894106</td>\n",
       "      <td>0.975893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.068404</td>\n",
       "      <td>0.894137</td>\n",
       "      <td>0.923931</td>\n",
       "      <td>0.908790</td>\n",
       "      <td>0.980927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.067391</td>\n",
       "      <td>0.903717</td>\n",
       "      <td>0.928812</td>\n",
       "      <td>0.916093</td>\n",
       "      <td>0.982060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2634, training_loss=0.09353885002541741, metrics={'train_runtime': 339.5724, 'train_samples_per_second': 124.056, 'train_steps_per_second': 7.757, 'total_flos': 525217416637032.0, 'train_loss': 0.09353885002541741, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:55:15.117568Z",
     "iopub.status.busy": "2023-09-29T14:55:15.116883Z",
     "iopub.status.idle": "2023-09-29T14:55:15.694566Z",
     "shell.execute_reply": "2023-09-29T14:55:15.693454Z",
     "shell.execute_reply.started": "2023-09-29T14:55:15.117530Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model('fine_tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T14:55:15.696379Z",
     "iopub.status.busy": "2023-09-29T14:55:15.695850Z",
     "iopub.status.idle": "2023-09-29T14:55:18.335813Z",
     "shell.execute_reply": "2023-09-29T14:55:18.334522Z",
     "shell.execute_reply.started": "2023-09-29T14:55:15.696341Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\n",
    "    'token-classification',\n",
    "    model = 'fine_tuned_model',\n",
    "    aggregation_strategy = 'simple' , \n",
    "    device = 0 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T15:05:22.749813Z",
     "iopub.status.busy": "2023-09-29T15:05:22.749477Z",
     "iopub.status.idle": "2023-09-29T15:05:22.773415Z",
     "shell.execute_reply": "2023-09-29T15:05:22.772205Z",
     "shell.execute_reply.started": "2023-09-29T15:05:22.749787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.9945988,\n",
       "  'word': 'Apple Inc.',\n",
       "  'start': 0,\n",
       "  'end': 10},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9955286,\n",
       "  'word': 'San Francisco',\n",
       "  'start': 46,\n",
       "  'end': 59},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9978052,\n",
       "  'word': 'California',\n",
       "  'start': 61,\n",
       "  'end': 71}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner('Apple Inc. is planning to open a new store in San Francisco, California.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dui",
   "language": "python",
   "name": "dui"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
